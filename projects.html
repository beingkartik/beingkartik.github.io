<!DOCTYPE html>

<html>
    <head>
        <title>Experience</title>
        <!-- link to main stylesheet -->
        <link href="https://fonts.googleapis.com/css?family=Lato:300,400" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/css/main_1.css">
    </head>
    <body>

        <nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<!-- <li><a href="/about">About</a></li> -->
        		<li><a href="/assets/resume_Kartik_Gupta.pdf">R‌&#233;sum‌&#233;</a></li>
        		<li><a href="/projects.html">Experience</a></li>
    		</ul>
		</nav>

        <h5> Research </h5>

        <table width="80%" align="center" border="0" cellspacing="0" cellpadding="20">
	  <tr>
              <td width="30%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/Research/chamfer_detect.png' style="width:300px;height:198px;">
                </div>
              </td>
              <td valign="top" width="70%">
                  <p>Vision based Edge Quality Control <br></p>
                  Kartik Gupta, Cindy Grimm, Burak Sencer, and Ravi Balasubramanian
		      <br>
                <anchor id="p_swaayatt_stereo" href=''></anchor>
		<p2>Designed a computer vision based system for high precision 6D pose estimation and evaluation of edge deburring quality (within 1-2 mm) 
			using an off-the-shelf camera for industrial application. The robustness and repeatability of the method are the 
			key challenges in the work. We published the work at MSEC 2020. I was scheduled to present the work at the conference. However, the
		      physical conference has been cancelled due to COVID-19.
		 </p2>     
              </td>
          </tr>	
		
		
	<tr>
              <td width="30%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/Research/grasping_paper.jpg' style="width:300px;height:178px;">
                </div>
              </td>
              <td valign="top" width="70%">
                  <p>Pose Tracking for Grasping Experiments <br></p>
                  
                <anchor id="p_swaayatt_stereo" href=''></anchor>
		<p2>I developed the computer vision pose tracking system to be able to perform grasping experiments. I was exposed to the robustness requirements
			of real life computer vision system. I also learned about grasping, its difficulties and strategies as I performed the experiments with 
			the co-authors. We published the work in the International Conference on Intelligent Robots and Systems(IROS) 2019 <a href="https://ieeexplore.ieee.org/document/8968468">[Report]</a>
		</p2>     
              </td>
          </tr>	
		

          <tr>
            <td width="30%">
              <div class="one">
<!--               <div class="two"><img src='friendly_after.png'></div>  -->
              <img src='/assets/Projects/agv_nav_2.png' style="width:300px;height:300px;">
              </div>
            </td>
            <td valign="top" width="70%">
                <p>Autonomous Ground Vehicle (AGV) Navigation in Orchards<br></p>
		    <i>Guide: Dr. Vason Srini, Executive Director, DataFlux Systems Inc., Berkeley, CA </i>
                <anchor id="p_research_calib" href=''></anchor>
             <br><br>
              <p2>I worked on autonomous generation of a navigational path across the orchards using aerial data obtained with the help of GoogleEarth images, for Autonomous Ground Vehicles (AGV) to be used in orchards. Implemented Canny Edge Detection and Contour Analysis to identify and classify the trees and obstructions. Performed noise filtration, least-squared error analysis and regression method to estimate the rows of trees. Further, I Incorporated Bezier curves created
using Controlled Random Search algorithm with C2 continuity to allow for high speeds at turns. This entire processing pipeline was developed as a ROS node 
		      which was incorporated with the navigation system of the AGV. The process achieved upto 95% accuracy in path generation and was robust to wide density of tree growth. <a href="/assets/Projects/agv_nav.pdf">[Report]</a><br>
             </p2>
            </td>
          </tr>
       </table>
       <h5> ABU ROBOCON :ASIAN OCEANIAN ROBOTICS COMPETITION </h5>
      <table width="80%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="30%">
            <div class="one">
<!--             comment out later <div class="two"><img src='friendly_after.png'></div> comment out later -->
            <img src='/assets/Projects/rcon15.jpg' style="width:240px;height:240px;">
            </div>
          </td>
          <td valign="top" width="70%">
            <anchor id="p_swaayatt_facepose" href=''></anchor>
            <p>Robocon 2015 - Badminton Playing Robots<br></p>
            <i>Team Robocon, IIT Kanpur</i><br>
<!--              <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>  -->
            <p2>We developed 2 Semi-Autonomous robots capable of playing badminton on full sized badminton court. We worked on automating the shuttle detection and localization process. We performed blob detection and optical flow with OpenCV for shuttle localisation using a Kinect sensor. Also, we implemented extended Kalman Filter for trajectory prediction. We achieved accurate prediction of trajectory and landing point of incoming shuttle within error margin of 5-7 cm. <a href="https://www.youtube.com/watch?v=9LFS0ITb_V4">[Video: Complete Robot]</a> <a href="https://www.youtube.com/watch?v=j2-H-IdrH8c&list=PLjbO0t7bHEd0BSOkIqFvy5wrqQvmC0yMC&index=3">[Video: Sensing]</a> <br></p2>
          </td>
        </tr>
        <tr>
          <td width="30%">
            <div class="one">
            <img src='/assets/Projects/rcon14.png' style="width:240px;height:180px;">
            </div>
          </td>
          <td valign="top" width="70%">
            <anchor id="p_swaayatt_tracker" href=''></anchor>
            <p>Robocon 14 - Autonomous Pole Walking Robot<br></p>
            <i>Team Robocon, IIT Kanpur</i><br>
            <p2>Developed a manual robot with holonomic motion and an autonomous robot capable of vertical pole traversal . The autonomous robot incorporated a stable closed-loop control system using motors, rotary encoders and multiple ultrasonic sensors to detect and grasp the poles to move the bot forward and for climbing ladders. The manual robot was developed with a joystick-controlled holonomic drive using omni wheels and feedback loop. Our team secured 6th place in the National Competition and bagged the award for Best Innovative Design. <a href="https://www.youtube.com/watch?v=hoDn82fd3Tk">[Pole walking Robot]</a> <br></p2>

          </td>
        </tr>
      </table>

<!--         <tr>
          <td width="25%">
            <div class="one">
            <img src='/assets/Projects/tracker_segmenter.jpg' style="width:240px;height:140px;">
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="p_embedded1" href=''></anchor>
            <p>Tracking and Segmentation of Vehicles for Annotation<br></p>
            <i>Swaayatt Robots, India</i><br>
            <p2>Annotation system for vehicle detection data. Propogating selected keypoints and feature points within vehicle boundaries using multi-scale template matching and particle filters. Results in a scale-changing contour of vehicles to be segmented. </p2>
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
                <iframe width="240" height="180" src="https://www.youtube.com/embed/YWjOEWO5lFs" frameborder="0" gesture="media" allowfullscreen></iframe>
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="p_embedded2" href=''></anchor>
            <p>Telepresence Robot with Stereoscopic Vision<br></p>
            <i>Final Year Project, TCET, Mumbai University</i><br>
            <p2>Small scale and inexpensive telepresence platform capable of streaming immersive 3D SBS live video feed (350x350 resolution, 40 fps). Base platform actuated using AtMega2560 and keyboard/console commands. Raspberry Pi with camera module receives axis-angle commands from smartphone to control a 2-DOF servo-gimbal.<br>
            Code: <a href="https://github.com/epiception/Virtual-Telepresence">[Telepresence bot]</a><br></p2>
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
                <iframe width="240" height="120" src="https://www.youtube.com/embed/yTIguJIK16Y" frameborder="0" gesture="media" allowfullscreen></iframe><br>
                <iframe width="240" height="120" src="https://www.youtube.com/embed/YmRXB2YnW48" frameborder="0" gesture="media" allowfullscreen></iframe>
            </div>
          </td>
          <td valign="top" width="75%">
            <p>Grid Traversing Robots<br></p>
            <i>eYantra Lab Setup Initiative, TCET, Mumbai University</i><br>
            <p2>1. Minesweeping Robot: Traverses a small grid to locate basic obstacles (mines) and display their co-ordinate locations after reaching the end point. Breadth First Search and Djikstras' Algorithms based traversal are demonstrated.<br><br>
            2. Warehouse Management Simulation: Implementation of a small scale automated supply chain using order picking algorithms. Objects are collected, sorted based on a requirement (eg. color) and then transported to the specified destination zone.<br><br>
            Developed on the Firebird-V AtMega2560 Robotics Research Platform, Nex Robotics, IIT-Bombay.
            Code: <a href="https://github.com/epiception/Mine-Localization-Robot-using-Firebird-V">[Mine Localization]</a> | <a href="https://github.com/epiception/Warehouse-Management-Using-FireBird-V">[Warehouse Management]</a><br></p2>
          </td>
        </tr>  -->
	      
 	<h5> Academic Projects </h5>

        <table width="80%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="25%">
              <div class="one">
<!--               <div class="two"><img src='friendly_after.png'></div>  -->
              <img src='/assets/gridworld.PNG' style="width:270px;height:270px;">
              </div>
            </td>
            <td valign="top" width="75%">
		    <p>Task Allocation in Multiagent Robotic Systems in a Warehouse</p>
<!-- 		    <i>Guide:Dr. Vason Srini,Executive Director,DataFlux Systems Inc., Berkeley, CA </i> -->
                <anchor id="p_research_calib" href=''></anchor>
             <br>
              <p2>We propose a distributed approach
in warehouse task allocation in which the multiagent system
use an evolutionary algorithm to exploit the best policies and
efficiently select tasks to complete in a warehouse simulation.
We use Cooperative Co-Evolutionary Algorithm with Hall of
Fame and Difference Evaluation to train the multiagent system
and compare its performance with a centralized approach commonly
used in most autonomous warehouses. We show that the
performance of the distributed system greatly outperforms the
centralized approach in allocating tasks. 
<a href="https://docs.google.com/presentation/d/1XugxAluqvHGDpK94--JZmGwRzrFAmiLC5paIAe9lHYo/edit?usp=sharing">[Presentation] 
	<a href="/assets/Task_Allocation_in_MultiAgent_Robotic_Systems_in_a_Warehouse_.pdf">[Report]</a></a>
             </p2>
            </td>
          </tr>
	
	  <tr>
            <td width="35%">
              <div class="one">
<!--               <div class="two"><img src='friendly_after.png'></div>  -->
              <img src='/assets/Projects/opticalflow.png' style="width:320px;height:180px;">
              </div>
            </td>
            <td valign="top" width="65%">
		    <p>Multi-Scale Frame Interpolation</p>
<!-- 		    <i>Guide:Dr. Vason Srini,Executive Director,DataFlux Systems Inc., Berkeley, CA </i> -->
                <anchor id="p_research_calib" href=''></anchor>
             <br>
              <p2>Proposed improving upon Nvidia’s SuperSloMo usingcoarse-to-fineimage generation with stage-wise train-ing and 
		      achieved competitive results. We also experimented with adding a GAN for further image refinement. 
<a href="https://docs.google.com/presentation/d/1bf1LrFqvNCiOPARnzMvBoO9R2jy5DzpsrId93ftuhXQ/edit?usp=sharing">[Presentation] 
	<a href="/assets/Projects/Variable_Length_Multi_Frame_Video_Interpolation_report.pdf">[Report]</a></a>
             </p2>
            </td>
          </tr>
	
	
	  <tr>
            <td width="35%">
              <div class="one">
<!--               <div class="two"><img src='friendly_after.png'></div>  -->
              <img src='/assets/Projects/mdp_architechture.png' style="width:306px;height:130px;">
              </div>
            </td>
            <td valign="top" width="65%">
		    <p>Benchmarking Motion Planning Networks</p>
<!-- 		    <i>Guide:Dr. Vason Srini,Executive Director,DataFlux Systems Inc., Berkeley, CA </i> -->
                <anchor id="p_research_calib" href=''></anchor>
             
              <p2>Incorporatedend-to-end learningfor contractive auto encoders with MPNet achieving10%improvement.
		      Extended MPNet for trajectory planning for 7DOF robot arm achieving faster planning compared to RRT*.
	<a href="/assets/Projects/ROB_534_SDM_Final_Project.pdf">[Report]</a>
             </p2>
            </td>
          </tr>
		
	  <tr>
              <td width="35%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/Projects/reduced_vision_pic.png' style="width:300px;height:240px;">
                </div>
              </td>
              <td valign="top" width="65%">
                  <p>SLAM in Reduced Vision<br></p>
                  Kartik Gupta, Ankit Pensia, Ramavtar Malav
                <i>Guide : Prof. Gaurav Pandey, Dept of Electrical Engineering, IIT Kanpur</i> <br><br>
                <anchor id="p_swaayatt_stereo" href=''></anchor>
		<p2>We worked to improve the accuracy of monocular SLAM in presence of smoke and fog using image processing technique of <a href="https://ieeexplore.ieee.org/document/5567108?reload=true"> Single Image Dehazing using Dark Channel Prior by He et al</a>. Dehazing enables us to increase scene visibility and extract seemingly invisible visual detail. Evaluation of results showed 450% increase in keyframe selection, over a wide range of fog density.  <a href="/assets/Projects/reduced_vision_report.pdf">[Report]</a></p2>     
              </td>
          </tr>
       </table>
	      
	      
	      
	      
 	<h6> Work Experience </h6>

        <table width="80%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
              <td width="30%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/OYO_Logo.png' style="width:270px;height:270px;">
                </div>
              </td>
              <td valign="top" width="70%">
		      <p>Data Scientist, <a href="https://www.oyorooms.com">OYO</a> <br></p>
                  <br><br>
                <anchor id="p_swaayatt_stereo" href=''></anchor>
		<p2>As part of the pricing team, I was involved in devising algorithms for dynamic pricing of 2500+ hotels across India, Nepal and Malaysia. We exploited vast domain of data to provide accurate occupancy predictions and current booking trends.  Also, we implemented K-means clustering and non linear regression to identify days of peak demand for each city to maximise revenue. As a key personal project, I worked on developing live elasticity model to model the pricing response.</p2>     
              </td>
          </tr>
          <tr>
            <td width="30%">
              <div class="one">
<!--               <div class="two"><img src='friendly_after.png'></div>  -->
              <img src='/assets/fastfox.png' style="width:270px;height:270px;">
              </div>
            </td>
            <td valign="top" width="70%">
		    <p>Business Analyst, <a href="https://fastfox.com">Fastfox.com</a> <br></p>
<!-- 		    <i>Guide:Dr. Vason Srini,Executive Director,DataFlux Systems Inc., Berkeley, CA </i> -->
                <anchor id="p_research_calib" href=''></anchor>
             <br><br>
              <p2>As a business analyst in this rapidly growing startup I was involved across a wide variety of work. I was responsible for multiple projects involving descriptive, diagnostic and prescriptive analytics across the breadth of the company including supply estimation, on-field failure reduction, marketing and SKU segmentation. I also performed multiple customer engagement and retention studies and suggested strategies to boost user retention and engagement. 
             </p2>
            </td>
          </tr>
       </table>

      <footer>
          <a style="float: right; padding-top: 25px;" href="https://jonbarron.info/">Template Credits</a>
<!--            <ul>
              <li><a href="mailto:giyer2309@gmail.com">email</a></li>
              <li><a href="https://github.com/epiception">github.com/epiception</a></li>
          </ul> -->
          <div class="footer-social-icons">
<!--               <h4 class="_14">Follow us on</h4>  -->
              <ul class="social-icons">
		<li><a href="https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=guptak@oregonstate.edu&su=Hello&shva=1" class="social-icon"> <i class="fa fa-envelope"></i></a></li>
		<li><a href="https://www.linkedin.com/in/kartikguptaprofile/" class="social-icon"> <i class="fa fa-linkedin"></i></a></li>
		<li><a href="https://github.com/beingkartik" class="social-icon"> <i class="fa fa-github"></i></a></li>
<!--                   <li><a href="https://www.youtube.com/user/giyer2309/videos?view_as=subscriber&sort=dd&view=0&shelf_id=0" class="social-icon"> <i class="fa fa-youtube"></i></a></li> -->
              </ul>
          </div>
      </footer>
    </body>

</html>
