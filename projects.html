<!DOCTYPE html>

<html>
    <head>
        <title>Projects</title>
        <!-- link to main stylesheet -->
        <link href="https://fonts.googleapis.com/css?family=Lato:300,400" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/css/main_1.css">
    </head>
    <body>

        <nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<!-- <li><a href="/about">About</a></li> -->
        		<li><a href="/assets/resume_16_oct_2018.pdf">R‌&#233;sum‌&#233;</a></li>
        		<li><a href="/projects.html">Experience</a></li>
    		</ul>
		</nav>

        <h4> Projects </h4>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
              <td width="25%">
                <div class="one">
                <!-- <div class="two"><img src='friendly_after.png'></div> -->
                <img src='/assets/Projects/reduced_vision_pic.png' style="width:250px;height:150px;">
                </div>
              </td>
              <td valign="top" width="75%">
                  <p>SLAM in Reduced Vision<br></p>
                  Kartik Gupta, Ankit Pensia, Ramavtar Malav
                <i>Guide : Prof. Gaurav Pandey, Dept of Electrical Engineering, IIT Kanpur</i> <br><br>
                <anchor id="p_swaayatt_stereo" href=''></anchor>
		<p2>We worked to improve the accuracy of monocular SLAM in presence of smoke and fog using image processing technique of <a href="https://ieeexplore.ieee.org/document/5567108?reload=true"> Single Image Dehazing using Dark Channel Prior by He et al</a>. Dehazing enables us to increase scene visibility and extract seemingly invisible visual detail. Evaluation of results showed 4.5 times improvement in keyframe selection, over a wide range of fog density. <a href="/assets/Projects/reduced_vision_report.pdf">[Report]</a></p2>     
              </td>
          </tr>
          <tr>
            <td width="25%">
              <div class="one">
<!--               <div class="two"><img src='friendly_after.png'></div>  -->
              <img src='/assets/Projects/agv_nav.jpg' style="width:250px;height:150px;">
              </div>
            </td>
            <td valign="top" width="75%">
                <p>Autonomous Ground Vehicle (AGV) Navigation in Orchards<br></p>
		    <i>Guide:Dr. Vason Srini,Executive Director,DataFlux Systems Inc., Berkeley, CA </i>
                <anchor id="p_research_calib" href=''></anchor>
             <br><br>
              <p2>I worked on autonomous generation of a navigational path across the orchards using aerial data obtained with the help of GoogleEarth images, for Autonomous Ground Vehicles (AGV) to be used in orchards. Implemented Canny Edge Detection and Contour Analysis to identify and classify the trees and obstructions. Performed noise filtration, least-squared error analysis and regression method to estimate the rows of trees. Further, I Incorporated Bezier curves created
using Controlled Random Search algorithm with C2 continuity to allow for high speeds at turns. This entire processing pipeline was developed as a ROS node which was incorporated with the rest of the system. The process achieved upto 95% accuracy in path generation and is effective over wide range of tree growth. <br><a href="/assets/Projects/agv_nav.pdf">[Report]</a>
             </p2>
            </td>
          </tr>
       </table>
       <h4> ABU ROBOCON :ASIAN OCEANIAN ROBOTICS COMPETITION </h4>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="25%">
            <div class="one">
<!--             comment out later <div class="two"><img src='friendly_after.png'></div> comment out later -->
            <img src='/assets/Projects/rcon15.jpg' style="width:240px;height:160px;">
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="p_swaayatt_facepose" href=''></anchor>
            <p>Robocon 2015 - Badminton Playing Robots<br></p>
            <i>Swaayatt Robots, India</i><br>
<!--              <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>  -->
            <p2>We developed 2 Semi-Autonomous robots capable of playing badminton on full sized badminton court. We worked on automating the shuttle detection and localization process. We performed blob detection and optical flow with OpenCV for shuttle localisation using a Kinect sensor. Also, we implemented extended Kalman Filter for trajectory prediction. We achieved accurate prediction of trajectory and landing point of incoming shuttle within error margin of 5-7 cm.<a href="https://www.youtube.com/watch?v=9LFS0ITb_V4">[Video]</a><br></p2>
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
            <img src='/assets/Projects/face_clouds_low.png' style="width:240px;height:140px;">
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="p_swaayatt_tracker" href=''></anchor>
            <p>RGBD Facial Pose tracking for Advanced Driver Assistance Systems<br></p>
            <i>Swaayatt Robots, India</i><br>
            <p2>Point Cloud Processing package for tracking the face pose and central axis of gaze for RGBD based Advanced Driver
                Assistance System. Alignment to standard model using 3D FPFH features for points and normals, Sampling Consensus and Iterative Closest Point.</p2>

          </td>
        </tr>

        <tr>
          <td width="25%">
            <div class="one">
            <img src='/assets/Projects/tracker_segmenter.jpg' style="width:240px;height:140px;">
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="p_embedded1" href=''></anchor>
            <p>Tracking and Segmentation of Vehicles for Annotation<br></p>
            <i>Swaayatt Robots, India</i><br>
            <p2>Annotation system for vehicle detection data. Propogating selected keypoints and feature points within vehicle boundaries using multi-scale template matching and particle filters. Results in a scale-changing contour of vehicles to be segmented. </p2>
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
                <iframe width="240" height="180" src="https://www.youtube.com/embed/YWjOEWO5lFs" frameborder="0" gesture="media" allowfullscreen></iframe>
            </div>
          </td>
          <td valign="top" width="75%">
            <anchor id="p_embedded2" href=''></anchor>
            <p>Telepresence Robot with Stereoscopic Vision<br></p>
            <i>Final Year Project, TCET, Mumbai University</i><br>
            <p2>Small scale and inexpensive telepresence platform capable of streaming immersive 3D SBS live video feed (350x350 resolution, 40 fps). Base platform actuated using AtMega2560 and keyboard/console commands. Raspberry Pi with camera module receives axis-angle commands from smartphone to control a 2-DOF servo-gimbal.<br>
            Code: <a href="https://github.com/epiception/Virtual-Telepresence">[Telepresence bot]</a><br></p2>
          </td>
        </tr>
        <tr>
          <td width="25%">
            <div class="one">
                <iframe width="240" height="120" src="https://www.youtube.com/embed/yTIguJIK16Y" frameborder="0" gesture="media" allowfullscreen></iframe><br>
                <iframe width="240" height="120" src="https://www.youtube.com/embed/YmRXB2YnW48" frameborder="0" gesture="media" allowfullscreen></iframe>
            </div>
          </td>
          <td valign="top" width="75%">
            <p>Grid Traversing Robots<br></p>
            <i>eYantra Lab Setup Initiative, TCET, Mumbai University</i><br>
            <p2>1. Minesweeping Robot: Traverses a small grid to locate basic obstacles (mines) and display their co-ordinate locations after reaching the end point. Breadth First Search and Djikstras' Algorithms based traversal are demonstrated.<br><br>
            2. Warehouse Management Simulation: Implementation of a small scale automated supply chain using order picking algorithms. Objects are collected, sorted based on a requirement (eg. color) and then transported to the specified destination zone.<br><br>
            Developed on the Firebird-V AtMega2560 Robotics Research Platform, Nex Robotics, IIT-Bombay.
            Code: <a href="https://github.com/epiception/Mine-Localization-Robot-using-Firebird-V">[Mine Localization]</a> | <a href="https://github.com/epiception/Warehouse-Management-Using-FireBird-V">[Warehouse Management]</a><br></p2>
          </td>
        </tr> 
      </table>

      <footer>
          <a style="float: right; padding-top: 25px;" href="https://jonbarron.info/">Template Credits</a>
<!--            <ul>
              <li><a href="mailto:giyer2309@gmail.com">email</a></li>
              <li><a href="https://github.com/epiception">github.com/epiception</a></li>
          </ul> -->
          <div class="footer-social-icons">
<!--               <h4 class="_14">Follow us on</h4>  -->
              <ul class="social-icons">
		<li><a href="mailto:guptak@oregonstate.edu" class="social-icon"> <i class="fa fa-envelope"></i></a></li>
		<li><a href="https://www.linkedin.com/in/kartikguptaprofile/" class="social-icon"> <i class="fa fa-linkedin"></i></a></li>
		<li><a href="https://github.com/beingkartik" class="social-icon"> <i class="fa fa-github"></i></a></li>
<!--                   <li><a href="https://www.youtube.com/user/giyer2309/videos?view_as=subscriber&sort=dd&view=0&shelf_id=0" class="social-icon"> <i class="fa fa-youtube"></i></a></li> -->
              </ul>
          </div>
      </footer>
    </body>

</html>
